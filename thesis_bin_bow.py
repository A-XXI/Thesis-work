# -*- coding: utf-8 -*-
"""Thesis_B_B.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_jg80k1Pm3TUb2N9QWAJeq359rRmnpk3
"""

import numpy as np
import pandas as pd

from google.colab import drive
drive.mount('/content/gdrive')

path="/content/gdrive/My Drive/Thesis/Data - Sheet1.csv"
data = pd.read_csv(path)

data.head()

!pip install -q wordcloud
import wordcloud
import nltk
import sklearn.metrics as metrics
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger') 

import io
import unicodedata
import string
import re
from sklearn import metrics
import itertools
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from sklearn.metrics import precision_score
from wordcloud import WordCloud

data['Hate'].isnull().sum()

x = data.drop(['Hate','Type'], axis=1)
y = data['Hate']
#x.head()
#y.head()

print(x.shape)
print(y.shape)

texts=x.copy()

texts['Comment'][2913]

import re
# Cleaning the texts
corpus = []
for i in range(0,len(texts)):
    review = re.sub('[^a-zA-Z]', ' ',str(texts['Comment'][i]))
    review = review.lower()
    review = review.split()
    review = ' '.join(review)
    corpus.append(review)

corpus[2913]

import matplotlib.pyplot as plt
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    See full source and example: 
    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html
    
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

#CounterVectorizer
#bag of words
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features=8000,ngram_range=(1,2))
X = cv.fit_transform(corpus).toarray()

## Divide the dataset into Train and Test
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)

from sklearn.linear_model import LogisticRegression
lgc=LogisticRegression()
lgc.fit(X_train, y_train)
pred = lgc.predict(X_test)
score = metrics.accuracy_score(y_test, pred)
print("accuracy:   %0.3f" % score)
from sklearn.metrics import precision_recall_fscore_support as score
precision, recall, fscore, support = score(y_test, pred,average='weighted')
print('precision: {}'.format(precision))
print('recall: {}'.format(recall))
print('fscore: {}'.format(fscore))
print('support: {}'.format(support))

cm = metrics.confusion_matrix(y_test, pred)
plot_confusion_matrix(cm, classes=['Hate', 'NonHate'])

### MultinomialNB Algorithm

from sklearn.naive_bayes import MultinomialNB
MNB=MultinomialNB()
MNB.fit(X_train, y_train)
pred = MNB.predict(X_test)
score = metrics.accuracy_score(y_test, pred)
print("accuracy:   %0.2f" % score)
from sklearn.metrics import precision_recall_fscore_support as score
precision, recall, fscore, support = score(y_test, pred, average='weighted')
print('precision: {}'.format(precision))
print('recall: {}'.format(recall))
print('fscore: {}'.format(fscore))
print('support: {}'.format(support))

cm = metrics.confusion_matrix(y_test, pred)
plot_confusion_matrix(cm, classes=['Hate', 'NonHate'])

### GaussianNB Algorithm

from sklearn.naive_bayes import GaussianNB
GNB = GaussianNB()
GNB.fit(X_train, y_train)
pred = GNB.predict(X_test)
score = metrics.accuracy_score(y_test, pred)
print("accuracy:   %0.2f" % score)
from sklearn.metrics import precision_recall_fscore_support as score
precision, recall, fscore, support = score(y_test, pred,average='weighted',zero_division=0)
print('precision: {}'.format(precision))
print('recall: {}'.format(recall))
print('fscore: {}'.format(fscore))
print('support: {}'.format(support))

cm = metrics.confusion_matrix(y_test, pred)
plot_confusion_matrix(cm, classes=['Hate', 'NonHate'])

### AdaBoostClassifier
from sklearn.ensemble import AdaBoostClassifier
ada= AdaBoostClassifier()
ada.fit(X_train, y_train)
pred = ada.predict(X_test)
score = metrics.accuracy_score(y_test, pred)
print("accuracy:   %0.3f" % score)
from sklearn.metrics import precision_recall_fscore_support as score
precision, recall, fscore, support = score(y_test, pred,average='weighted')
print('precision: {}'.format(precision))
print('recall: {}'.format(recall))
print('fscore: {}'.format(fscore))
print('support: {}'.format(support))

cm = metrics.confusion_matrix(y_test, pred)
plot_confusion_matrix(cm, classes=['Hate', 'NonHate'])

### DecisionTreeClassifier
from sklearn.tree import DecisionTreeClassifier
dc=DecisionTreeClassifier(max_depth=3)
dc.fit(X_train, y_train)
pred = dc.predict(X_test)
score = metrics.accuracy_score(y_test, pred)
print("accuracy:   %0.2f" % score)
from sklearn.metrics import precision_recall_fscore_support as score
precision, recall, fscore, support = score(y_test, pred,average='weighted')
print('precision: {}'.format(precision))
print('recall: {}'.format(recall))
print('fscore: {}'.format(fscore))
print('support: {}'.format(support))

cm = metrics.confusion_matrix(y_test, pred)
plot_confusion_matrix(cm, classes=['Hate', 'NonHate'])

### RandomForestClassifier

from sklearn.ensemble import RandomForestClassifier
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)
pred = rf_model.predict(X_test)
score = metrics.accuracy_score(y_test, pred)
print("accuracy:   %0.3f" % score)
from sklearn.metrics import precision_recall_fscore_support as score
precision, recall, fscore, support = score(y_test, pred,average='weighted')
print('precision: {}'.format(precision))
print('recall: {}'.format(recall))
print('fscore: {}'.format(fscore))
print('support: {}'.format(support))

cm = metrics.confusion_matrix(y_test, pred)
plot_confusion_matrix(cm, classes=['Hate', 'NonHate'])

from sklearn.svm import SVC
svc = SVC(C=1,kernel='linear',gamma = 'auto',probability=True)
svc.fit(X_train, y_train)
pred = svc.predict(X_test)
score = metrics.accuracy_score(y_test, pred)
print("accuracy:   %0.3f" % score)
from sklearn.metrics import precision_recall_fscore_support as score
precision, recall, fscore, support = score(y_test, pred,average='weighted')
print('precision: {}'.format(precision))
print('recall: {}'.format(recall))
print('fscore: {}'.format(fscore))
print('support: {}'.format(support))

cm = metrics.confusion_matrix(y_test, pred)
plot_confusion_matrix(cm, classes=['Hate', 'NonHate'])